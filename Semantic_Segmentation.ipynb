{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JpM2fhIkqSgR"
      },
      "outputs": [],
      "source": [
        "from os.path import join, isdir\n",
        "from os import listdir, rmdir\n",
        "from shutil import move, rmtree, make_archive\n",
        "\n",
        "import os\n",
        "import cv2\n",
        "import glob\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.models import Sequential, Model, load_model\n",
        "from keras.layers import Dense, Input, Dropout, Activation, Flatten, BatchNormalization, ReLU, LeakyReLU, concatenate\n",
        "from keras.layers import Conv2D, MaxPooling2D, UpSampling2D, AveragePooling2D, GlobalAveragePooling2D, Add\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/gdrive')\n",
        "drive_root = '/gdrive/My Drive/Project/Semantic Segmentation/'\n",
        "\n",
        "COLAB_DIR = '/content/'\n",
        "GT_DIR = COLAB_DIR + 'gtFine/gtFine/'\n",
        "IMG_DIR = COLAB_DIR + 'leftImg/leftImg8bit/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YFj83NzhqdXN"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "11_Lmk0FqXAX"
      },
      "outputs": [],
      "source": [
        "!pip install cityscapesscripts\n",
        "from cityscapesscripts.download import downloader\n",
        "\n",
        "#login on cityscapes website\n",
        "\n",
        "session = downloader.login()\n",
        "downloader.get_available_packages(session=session)\n",
        "\n",
        "# downloading data\n",
        "print('Downloading gtFine and leftImg8bit packages ...\\n')\n",
        "package_list =['gtFine_trainvaltest.zip', 'leftImg8bit_trainvaltest.zip']\n",
        "downloader.download_packages(session=session, package_names=package_list, destination_path=COLAB_DIR)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "_vpKiixuqyX-"
      },
      "outputs": [],
      "source": [
        "!unzip -q gtFine_trainvaltest.zip -d gtFine\n",
        "!unzip -q leftImg8bit_trainvaltest.zip -d leftImg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ryk157gGrNQ2"
      },
      "outputs": [],
      "source": [
        "# collapse child directories\n",
        "for parent in listdir(GT_DIR):\n",
        "    parent_dir = GT_DIR + parent\n",
        "    for child in listdir(parent_dir):\n",
        "        if isdir(join(parent_dir, child)):\n",
        "            keep = glob.glob(join(parent_dir, child) + '/*_gtFine_color.png')\n",
        "            keep = [f.split('/')[-1] for f in keep]\n",
        "            for filename in list(set(listdir(join(parent_dir, child))) & set(keep)):\n",
        "                move(join(parent_dir, child, filename), join(parent_dir, filename))\n",
        "            rmtree(join(parent_dir, child))\n",
        "\n",
        "for parent in listdir(IMG_DIR):\n",
        "    parent_dir = IMG_DIR + parent\n",
        "    for child in listdir(parent_dir):\n",
        "        if isdir(join(parent_dir, child)):\n",
        "            for filename in listdir(join(parent_dir, child)):\n",
        "                move(join(parent_dir, child, filename), join(parent_dir, filename))\n",
        "            rmtree(join(parent_dir, child))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "a6LFtzRCrNOY"
      },
      "outputs": [],
      "source": [
        "# process and archive image in smaller size\n",
        "IMG_SHAPE = 300,300\n",
        "\n",
        "gt_train_paths = [GT_DIR+'train/' + path for path in listdir(GT_DIR+'train/')]\n",
        "gt_test_paths = [GT_DIR+'test/' + path for path in listdir(GT_DIR+'test/')]\n",
        "gt_val_paths = [GT_DIR+'val/' + path for path in listdir(GT_DIR+'val/')]\n",
        "gt_paths = gt_train_paths + gt_test_paths + gt_val_paths\n",
        "\n",
        "im_train_paths = [IMG_DIR+'train/' + path for path in listdir(IMG_DIR+'train/')]\n",
        "im_test_paths = [IMG_DIR+'test/' + path for path in listdir(IMG_DIR+'test/')]\n",
        "im_val_paths = [IMG_DIR+'val/' + path for path in listdir(IMG_DIR+'val/')]\n",
        "im_paths = im_train_paths + im_test_paths + im_val_paths\n",
        "\n",
        "def resize_image(path):\n",
        "    img = Image.open(path)\n",
        "    img.thumbnail(IMG_SHAPE)\n",
        "    out_file = join(path)\n",
        "    img.save(out_file, 'PNG')\n",
        "\n",
        "for img in gt_paths + im_paths:\n",
        "    resize_image(img)\n",
        "\n",
        "make_archive('gtFine', 'zip', GT_DIR)\n",
        "make_archive('leftImg', 'zip', IMG_DIR)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "uIKX5KQkrNL-"
      },
      "outputs": [],
      "source": [
        "def download_if_missing(url, target, extract=True):\n",
        "    if os.path.exists(target):\n",
        "        return target\n",
        "    return tf.keras.utils.get_file(target, origin=url, extract=extract)\n",
        "\n",
        "gt_url_file = 'https://storage.googleapis.com/cityscapes_dataset/gtFine_trainvaltest.zip'\n",
        "im_url_file = 'https://storage.googleapis.com/cityscapes_dataset/leftImg8bit_trainvaltest.zip'\n",
        "\n",
        "gt_file, gt_dir = join(COLAB_DIR + 'gtFine.zip'), join(COLAB_DIR + 'gtFine/')\n",
        "im_file, im_dir = join(COLAB_DIR + 'leftImg.zip'), join(COLAB_DIR + 'leftImg/')\n",
        "\n",
        "download_if_missing(gt_url_file, gt_file, extract=False)\n",
        "download_if_missing(im_url_file, im_file, extract=False)\n",
        "\n",
        "!unzip -q $gt_file -d $gt_dir\n",
        "!unzip -q $im_file -d $im_dir"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "s9w-BmilrNJb"
      },
      "outputs": [],
      "source": [
        "# normalize image pixels\n",
        "IMG_SIZE = 299\n",
        "BATCH_SIZE = 32\n",
        "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
        "\n",
        "GT_DIR = COLAB_DIR + 'gtFine/'\n",
        "IMG_DIR = COLAB_DIR + 'leftImg/'\n",
        "\n",
        "def load_and_preprocess_image(path):\n",
        "    img = tf.io.read_file(path)\n",
        "    img = tf.image.decode_jpeg(img, channels=3)\n",
        "    img = tf.image.resize(img, [IMG_SIZE, IMG_SIZE])\n",
        "    img /= 255.0\n",
        "    return img\n",
        "\n",
        "def get_image_paths(dir):\n",
        "    return sorted([dir + path for path in listdir(dir)])\n",
        "\n",
        "# create tf.Dataset objects\n",
        "gt_train_ds = tf.data.Dataset.from_tensor_slices(get_image_paths(GT_DIR+'train/'))\n",
        "gt_val_ds = tf.data.Dataset.from_tensor_slices(get_image_paths(GT_DIR+'val/'))\n",
        "gt_test_ds = tf.data.Dataset.from_tensor_slices(get_image_paths(GT_DIR+'test/'))\n",
        "\n",
        "gt_train_ds = gt_train_ds.map(load_and_preprocess_image)\n",
        "gt_val_ds = gt_val_ds.map(load_and_preprocess_image)\n",
        "gt_test_ds = gt_test_ds.map(load_and_preprocess_image)\n",
        "\n",
        "im_train_ds = tf.data.Dataset.from_tensor_slices(get_image_paths(IMG_DIR+'train/'))\n",
        "im_val_ds = tf.data.Dataset.from_tensor_slices(get_image_paths(IMG_DIR+'val/'))\n",
        "im_test_ds = tf.data.Dataset.from_tensor_slices(get_image_paths(IMG_DIR+'test/'))\n",
        "\n",
        "im_train_ds = im_train_ds.map(load_and_preprocess_image)\n",
        "im_val_ds = im_val_ds.map(load_and_preprocess_image)\n",
        "im_test_ds = im_test_ds.map(load_and_preprocess_image)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "RkLZUCcQrNGt"
      },
      "outputs": [],
      "source": [
        "def visualize_images(img, gt, pred):\n",
        "    if pred is not None:\n",
        "        fig, axes = plt.subplots(1, 3, figsize=(12, 8))\n",
        "    else:\n",
        "        fig, axes = plt.subplots(1, 2, figsize=(8, 8))\n",
        "\n",
        "    axes[0].imshow(img)\n",
        "    axes[0].set_title('Actual Image')\n",
        "\n",
        "    axes[1].imshow(gt)\n",
        "    axes[1].set_title('Masked Image')\n",
        "\n",
        "    if pred is not None:\n",
        "        axes[2].imshow(pred)\n",
        "        axes[2].set_title('Predicted Image')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "lzpP48n2rnda"
      },
      "outputs": [],
      "source": [
        "for img, gt in list(zip(im_train_ds.take(2), gt_train_ds.take(2))):\n",
        "    visualize_images(img, gt, None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "_O2qaiWxrnaS"
      },
      "outputs": [],
      "source": [
        "def conv_block(X,filters,block):\n",
        "    # resiudal block with dilated convolutions\n",
        "    # add skip connection at last after doing convoluion\n",
        "\n",
        "    b = 'block_'+str(block)+'_'\n",
        "    f1,f2,f3 = filters\n",
        "    X_skip = X\n",
        "\n",
        "    # block_a\n",
        "    X = Conv2D(filters=f1,kernel_size=(1,1),dilation_rate=(1,1),\n",
        "               padding='same',kernel_initializer='he_normal',name=b+'a')(X)\n",
        "    X = BatchNormalization(name=b+'batch_norm_a')(X)\n",
        "    X = LeakyReLU(alpha=0.2,name=b+'leakyrelu_a')(X)\n",
        "    # block_b\n",
        "    X = Conv2D(filters=f2,kernel_size=(3,3),dilation_rate=(2,2),\n",
        "               padding='same',kernel_initializer='he_normal',name=b+'b')(X)\n",
        "    X = BatchNormalization(name=b+'batch_norm_b')(X)\n",
        "    X = LeakyReLU(alpha=0.2,name=b+'leakyrelu_b')(X)\n",
        "    # block_c\n",
        "    X = Conv2D(filters=f3,kernel_size=(1,1),dilation_rate=(1,1),\n",
        "               padding='same',kernel_initializer='he_normal',name=b+'c')(X)\n",
        "    X = BatchNormalization(name=b+'batch_norm_c')(X)\n",
        "    # skip_conv\n",
        "    X_skip = Conv2D(filters=f3,kernel_size=(3,3),padding='same',name=b+'skip_conv')(X_skip)\n",
        "    X_skip = BatchNormalization(name=b+'batch_norm_skip_conv')(X_skip)\n",
        "    # block_c + skip_conv\n",
        "    X = Add(name=b+'add')([X,X_skip])\n",
        "    X = ReLU(name=b+'relu')(X)\n",
        "    return X\n",
        "\n",
        "def base_feature_maps(input_layer):\n",
        "    # base covolution module to get input image feature maps\n",
        "\n",
        "    # block_1\n",
        "    base = conv_block(input_layer,[16,16,32],'1')\n",
        "    # block_2\n",
        "    base = conv_block(base,[16,16,32],'2')\n",
        "    return base\n",
        "\n",
        "def pyramid_feature_maps(input_layer):\n",
        "    # pyramid pooling module\n",
        "\n",
        "    base = base_feature_maps(input_layer)\n",
        "    # red\n",
        "    red = GlobalAveragePooling2D(name='red_pool')(base)\n",
        "    red = tf.keras.layers.Reshape((1,1,32))(red)\n",
        "    red = Conv2D(filters=32,kernel_size=(1,1),name='red_1_by_1')(red)\n",
        "    red = UpSampling2D(size=128,interpolation='bilinear',name='red_upsampling')(red)\n",
        "    red = tf.image.resize(red, [IMG_SIZE, IMG_SIZE])\n",
        "    # yellow\n",
        "    yellow = AveragePooling2D(pool_size=(2,2),name='yellow_pool')(base)\n",
        "    yellow = Conv2D(filters=32,kernel_size=(1,1),name='yellow_1_by_1')(yellow)\n",
        "    yellow = UpSampling2D(size=2,interpolation='bilinear',name='yellow_upsampling')(yellow)\n",
        "    yellow = tf.image.resize(yellow, [IMG_SIZE, IMG_SIZE])\n",
        "    # blue\n",
        "    blue = AveragePooling2D(pool_size=(4,4),name='blue_pool')(base)\n",
        "    blue = Conv2D(filters=32,kernel_size=(1,1),name='blue_1_by_1')(blue)\n",
        "    blue = UpSampling2D(size=4,interpolation='bilinear',name='blue_upsampling')(blue)\n",
        "    blue = tf.image.resize(blue, [IMG_SIZE, IMG_SIZE])\n",
        "    # green\n",
        "    green = AveragePooling2D(pool_size=(8,8),name='green_pool')(base)\n",
        "    green = Conv2D(filters=32,kernel_size=(1,1),name='green_1_by_1')(green)\n",
        "    green = UpSampling2D(size=8,interpolation='bilinear',name='green_upsampling')(green)\n",
        "    green = tf.image.resize(green, [IMG_SIZE, IMG_SIZE])\n",
        "    # base + red + yellow + blue + green\n",
        "    return tf.keras.layers.concatenate([base,red,yellow,blue,green])\n",
        "\n",
        "def last_conv_module(input_layer):\n",
        "    X = pyramid_feature_maps(input_layer)\n",
        "    X = Conv2D(filters=3,kernel_size=3,padding='same',name='last_conv_3_by_3')(X)\n",
        "    X = BatchNormalization(name='last_conv_3_by_3_batch_norm')(X)\n",
        "    X = Activation('sigmoid',name='last_conv_relu')(X)\n",
        "    return X"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "RO1dpi78rnXW"
      },
      "outputs": [],
      "source": [
        "input_shape = list(im_train_ds.take(1))[0].shape\n",
        "input_layer = tf.keras.Input(shape=input_shape, name='input')\n",
        "output_layer = last_conv_module(input_layer)\n",
        "\n",
        "model = tf.keras.Model(inputs=input_layer, outputs=output_layer)\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "TILeGLl6rzfD"
      },
      "outputs": [],
      "source": [
        "train_ds = tf.data.Dataset.zip((im_train_ds, gt_train_ds))\n",
        "train_ds = train_ds.cache().batch(BATCH_SIZE).prefetch(buffer_size=AUTOTUNE)\n",
        "\n",
        "val_ds = tf.data.Dataset.zip((im_val_ds, gt_val_ds))\n",
        "val_ds = val_ds.cache().batch(BATCH_SIZE).prefetch(buffer_size=AUTOTUNE)\n",
        "\n",
        "test_ds = tf.data.Dataset.zip((im_test_ds, gt_test_ds))\n",
        "test_ds = test_ds.cache().batch(BATCH_SIZE).prefetch(buffer_size=AUTOTUNE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "M7BQl39SAz8_"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.callbacks import TensorBoard\n",
        "\n",
        "tensorboard=TensorBoard(log_dir=drive_root+'logs/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "49Mf6HM9r1gC"
      },
      "outputs": [],
      "source": [
        "checkpoint_path = drive_root+'pspnet/cp.ckpt'\n",
        "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
        "\n",
        "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
        "                                                 save_weights_only=True,\n",
        "                                                 verbose=1)\n",
        "es_callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=2)\n",
        "\n",
        "model.compile(optimizer='adam', loss='mse', metrics='accuracy')\n",
        "history = model.fit(train_ds, validation_data=val_ds, epochs=5,\n",
        "                    callbacks=[cp_callback, es_callback])\n",
        "model.save(drive_root + 'PSPNet_semantic_segmentation_5.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5ykxgzhmr3uh"
      },
      "outputs": [],
      "source": [
        "def plot(history):\n",
        "  acc = history.history['accuracy']\n",
        "  val_acc = history.history['val_accuracy']\n",
        "  loss = history.history['loss']\n",
        "  val_loss = history.history['val_loss']\n",
        "\n",
        "  epochs = range(1,len(acc)+1)\n",
        "\n",
        "  plt.title('Training and validation accuracy')\n",
        "  plt.plot(epochs, acc, color='blue', label='Train')\n",
        "  plt.plot(epochs, val_acc, color='orange', label='Val')\n",
        "  plt.xlabel('Epoch')\n",
        "  plt.ylabel('Accuracy')\n",
        "  plt.legend()\n",
        "\n",
        "  _ = plt.figure()\n",
        "  plt.title('Training and validation loss')\n",
        "  plt.plot(epochs, loss, color='blue', label='Train')\n",
        "  plt.plot(epochs, val_loss, color='orange', label='Val')\n",
        "  plt.xlabel('Epoch')\n",
        "  plt.ylabel('Loss')\n",
        "  plt.legend()\n",
        "\n",
        "plot(history)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wRbxKpezsDFN"
      },
      "outputs": [],
      "source": [
        "pred_test_ds = model.predict(train_ds)\n",
        "\n",
        "for img, gt, pred in list(zip(im_train_ds.take(5), gt_train_ds.take(5), pred_test_ds)):\n",
        "    visualize_images(img, gt, pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X2stqkYLAHZD"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "authorship_tag": "ABX9TyM9OiqGmkQNM5wU8pl48fGR"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}